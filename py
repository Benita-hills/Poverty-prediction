# -*- coding: utf-8 -*-
"""poverty 5k prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Om19OpKAdACnjAJcYdJ_0Leb61s6rf7j

# Poverty Prediction Model
The data for this model was sourced from Living Standards Survey 2018-2019 by the National Bureau of Statistics (NBS) [view data source here](https://microdata.worldbank.org/index.php/catalog/3827).
Each row represents each household and each column is a feature

> The goal of the model is to classify households as either above or below the poverty line based on demographic and economic factors

1. Importing Libraries and Dataset
"""

# Import the neccesary library for data manipulation and analysis

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

# Create a Function to load data from an Excel file and perform basic preprocessing
def load_and_preprocess_data(file_path):
  df = pd.read_excel(file_path)
  return df

# Specify the path to the poverty prediction dataset

file_path = "/content/5000 poverty rprediction (2).xlsx"

df = load_and_preprocess_data(file_path)

"""2. Summary Statistics

Mean: The average value of each numeric column. This is useful for understanding the overall trend in your data.

Standard Deviation: The standard deviation indicates how spread out the values are from the mean. A large standard deviation suggests that the data points vary widely from the mean, while a small one indicates that most data points are close to the mean.

Min and Max: The minimum and maximum values provide the range of data. This is particularly useful for identifying any extreme values or outliers.

> Sector:1- Urban, 2- Poor

> Zone: 1- North-Central, 2-North-East, 3-North-West, 4-South-East,5-South-South, 6-South-West

> Education level - 0- No formal education, 1- Some primary education, 2- Completed primary school, 3-Some secondary education, 4-Completed secondary school, 5- Some post-secondary education (e.g., vocational training), 6-	Completed higher education (e.g.,college of education or diploma) 7- University degree or higher (Bachelor's degree, Master's, etc.)
"""

# prompt: count   hhid by Gender type ,

# Count hhid by Gender type
hhid_by_gender = df.groupby('Gender')['hhid'].count()
hhid_by_gender

df.describe()

# count of educational level type by number of observation top 5
education_counts = df['Educational Level'].value_counts().head(5)

# Print the top 5 education levels and their counts
print("Top 5 Education Levels and their counts:")
education_counts

#  visualizing Top 5 Education Levels and their counts using a bar chart.

# Assuming 'education_counts' is a pandas Series as calculated in the previous code
education_counts.plot(kind='bar', color='green')
plt.xlabel("Education Level")
plt.ylabel("Count")
plt.title("Top 5 Education Levels and their Counts")
plt.show()

#  count   hhid by zone rename North-Central, 2-North-East, 3-North-West, 4-South-East,5-South-South, 6-South-West

# Rename zone values
zone_mapping = {
    1: 'North-Central',
    2: 'North-East',
    3: 'North-West',
    4: 'South-East',
    5: 'South-South',
    6: 'South-West'
}
df['Zone'] = df['zone'].map(zone_mapping)

# Count hhid by zone
hhid_by_zone = df.groupby('Zone')['hhid'].count()
hhid_by_zone

"""3. Data Cleaning and Preparation"""

# Print the number of missing (null) values in each column of the DataFrame
print(df.isnull().sum())

# Fill missing values in 'Access to electricity' with the median
df['Access to electricity'] = df['Access to electricity'].fillna(df['Access to electricity'].median())

# drop a column

# Drop specified columns
columns_to_drop = ['state', 'lga', 'wt_final', 'popw', 'totcons_pc','Income source']
df = df.drop(columns=columns_to_drop, errors='ignore')

# Define a function to detect outliers in a specific feature using the IQR (Interquartile Range) method
def detect_outliers_iqr(df, feature):

    # Calculate the Q1 (25th percentile) and Q3 (75th percentile)
    Q1 = df[feature].quantile(0.25)
    Q3 = df[feature].quantile(0.75)

    # Calculate the Interquartile Range (IQR)
    IQR = Q3 - Q1

    # Calculate the lower and upper bounds for outliers
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Return a boolean series that marks outliers (True for outliers)
    return (df[feature] < lower_bound) | (df[feature] > upper_bound)

# Apply the IQR outlier detection for all numerical columns in the dataset
numerical_columns = df.select_dtypes(include=[np.number]).columns

outliers = pd.DataFrame()

for col in numerical_columns:
    outliers[col] = detect_outliers_iqr(df, col)

df.head()

"""# 4. Model Preparation

> Nigeria’s national poverty line was computed using consumption of both food and nonfood items. This gives the national poverty line of 137,430 naira per person per year; this equates to roughly 1.93 USD 2011 PPP per person per day (Source;NBS,World Bank 2019)


"""

# Define the national poverty line threshold (in local currency) used to classify households as poor or non-poor
poverty_line = 137430

# Create a binary target column 'poor' where 1 indicates consumption per capita is below the poverty line (i.e., poor), and 0 otherwise

df['poor'] = (df["Consumption per capita"] < poverty_line).astype(int)

# Select relevant features (independent variables) from the dataset for model training
X=df[['hhsize', 'Educational Level','Spending on food Items', 'Spending on non food items']]

# Define the target variable (dependent variable) — whether a household is poor or not
y=df['poor']

#  Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# : Train the model (Random Forest)
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Get feature importance
importances = model.feature_importances_
feature_names = X.columns
sorted_idx = importances.argsort()

# Plot
plt.figure(figsize=(10, 6))
plt.barh(feature_names[sorted_idx], importances[sorted_idx])
plt.xlabel("Feature Importance")
plt.title("Random Forest - Feature Importance")
plt.show()

# Step 6: Evaluate the model performance
y_pred = model.predict(X_test)

"""

> Evaluation metrics, such as confusion matrix, accuracy, precision, recall, F1 score,  are employed to assess the performance of predictive models

"""

# Calculate performance metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Model Evaluation:")
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
print("Confusion Matrix:")
print("Classification Report:")
print(report)

# A line chart to show predicted and actual value

# Assuming y_test and y_pred are already defined from your model evaluation
# Example data (replace with your actual y_test and y_pred)
y_test = [0, 1, 0, 1, 0, 1, 0, 0, 1, 1]
y_pred = [0, 0, 1, 1, 0, 0, 1, 0, 1, 0]


plt.figure(figsize=(10, 6))
plt.plot(range(len(y_test)), y_test, label='Actual Values', marker='o', linestyle='-')
plt.plot(range(len(y_pred)), y_pred, label='Predicted Values', marker='x', linestyle='--')
plt.xlabel("Data Point")
plt.ylabel("Value")
plt.title("Predicted vs. Actual Values")
plt.legend()
plt.grid(True)
plt.show()

# Function to accept user input for household characteristics and predict poverty status

def get_user_input_and_predict():
    # Accept user input for relevant features
    print("\nEnter the details of the household to predict the poverty:")
    hhsize = int(input("Enter household size: "))  # Collect input for household size
    educational_level = int(input("Enter educational level (numeric value): "))  # Collect input for education level
    spending_food = float(input("Enter spending on food items: "))  # Collect input for food spending
    spending_non_food = float(input("Enter spending on non-food items: "))  # Collect input for non-food spending
    return pd.DataFrame([[hhsize, educational_level, spending_food, spending_non_food]],
                        columns=['hhsize',  'Educational Level', 'Spending on food Items', 'Spending on non food items'])

user_input = get_user_input_and_predict()

print(user_input)

# Predict using the trained model
def predict_poverty(user_input):
    prediction = model.predict(user_input)
    prediction = prediction[0]
    print(prediction)
    if prediction == 1:
        print("The household is predicted to be BELOW the poverty line (Poor).")
    else:
        print("The household is predicted to be ABOVE the poverty line (Not Poor).")

predict_poverty(user_input)


